# ğŸ§  Bloom Agent: Asistente AR de Aprendizaje Cognitivo

![Unity](https://img.shields.io/badge/Unity-2022.3%20LTS-black?style=flat&logo=unity)
![Platform](https://img.shields.io/badge/Platform-Android%20(ARCore)-green?style=flat&logo=android)
![AI](https://img.shields.io/badge/AI-Groq%20%7C%20Llama3-orange?style=flat&logo=openai)
![License](https://img.shields.io/badge/License-MIT-blue?style=flat)

> **Proyecto de InteracciÃ³n Humano-Computadora (HCI)**
> Sistema de Realidad Aumentada mÃ³vil para el refuerzo del aprendizaje basado en la TaxonomÃ­a de Bloom (Niveles 1-4) mediante un asistente inteligente interactivo.

---

## ğŸ“– DescripciÃ³n del Proyecto

**Bloom Agent** es una aplicaciÃ³n de Realidad Aumentada (AR) diseÃ±ada para democratizar el aprendizaje inmersivo utilizando dispositivos mÃ³viles estÃ¡ndar. El sistema despliega un **Robot Asistente** y **Tarjetas HologrÃ¡ficas** sobre el escritorio fÃ­sico del estudiante, transformando cualquier entorno en un espacio de estudio activo.

El nÃºcleo del proyecto integra **Inteligencia Artificial Generativa** (vÃ­a Groq API) para leer documentos PDF proporcionados por el usuario y generar desafÃ­os adaptativos en tiempo real, clasificados segÃºn los niveles cognitivos de Bloom: *Recordar, Comprender, Aplicar y Analizar*.

---

## ğŸš€ CaracterÃ­sticas Principales

### ğŸ¤– DimensiÃ³n IA (Cerebro Cognitivo)
* [cite_start]**GeneraciÃ³n Procedural:** Uso de **Groq API (LPU)** con modelos **Llama-3-8b** o **Mixtral** para crear preguntas Ãºnicas en milisegundos[cite: 667, 671].
* **Adaptabilidad:** El sistema evalÃºa las respuestas y ajusta la dificultad o el nivel de Bloom automÃ¡ticamente.
* [cite_start]**Salida Estructurada:** GarantÃ­a de formato JSON para la integraciÃ³n perfecta con Unity[cite: 563].

### ğŸ“± DimensiÃ³n AR (Entorno)
* [cite_start]**DetecciÃ³n de Planos:** Escaneo de superficies horizontales (mesas/escritorios) usando **AR Foundation**[cite: 45].
* [cite_start]**Anclaje Espacial:** Persistencia de objetos virtuales (Robot y UI) en coordenadas del mundo real para evitar el "deslizamiento"[cite: 46].
* [cite_start]**Interfaz DielÃ©ctrica:** Burbujas de texto y menÃºs flotantes integrados en el espacio 3D (World Space Canvas)[cite: 36].

### ğŸ‘† DimensiÃ³n HCI (InteracciÃ³n)
* [cite_start]**Raycasting TÃ¡ctil:** InteracciÃ³n mediante "Taps" en pantalla traducidos a coordenadas 3D, minimizando la carga cognitiva[cite: 38].
* [cite_start]**Feedback Multimodal:** Respuesta visual (partÃ­culas/colores), animaciones del robot (celebraciÃ³n/pensar) y respuesta hÃ¡ptica (vibraciÃ³n)[cite: 270, 271].
* [cite_start]**Usabilidad MÃ³vil:** DiseÃ±ado para sesiones de micro-aprendizaje (3-5 min) para evitar fatiga fÃ­sica ("Gorilla Arm")[cite: 701].

---

## ğŸ› ï¸ Stack TecnolÃ³gico

* [cite_start]**Motor:** Unity 2022.3 LTS (Universal Render Pipeline - URP)[cite: 651, 656].
* [cite_start]**AR Framework:** AR Foundation 5.x + Google ARCore XR Plugin[cite: 653, 655].
* **Lenguaje:** C# (Scripting lÃ³gico y conexiÃ³n API).
* [cite_start]**Inteligencia Artificial:** Groq API (RESTful architecture)[cite: 666].
* [cite_start]**Formato de Datos:** JSON (Newtonsoft.Json)[cite: 673].

---

## ğŸ—ï¸ Arquitectura del Sistema

El sistema opera bajo una arquitectura de **Cliente Pesado (Thick Client)** con inteligencia externalizada:

1.  **Capa de PercepciÃ³n (Unity):** Gestiona la cÃ¡mara, detecciÃ³n de planos y renderizado.
2.  **Capa de Control (C#):** Administra el estado de la sesiÃ³n y las interacciones tÃ¡ctiles.
3.  **Capa Cognitiva (Groq Cloud):** Recibe el contexto (texto del PDF) + Nivel Bloom y retorna el objeto JSON.

> *Ver diagrama de arquitectura detallado en `/Docs/Architecture.png`*

---

## ğŸ“‹ Requisitos de InstalaciÃ³n

### Hardware (Dispositivo de Despliegue)
* **Dispositivo:** Smartphone Android.
* [cite_start]**OS:** Android 10.0 (API Nivel 29) o superior[cite: 678].
* [cite_start]**Soporte:** Compatible con Google Play Services for AR (ARCore)[cite: 679].
* **Sensores:** CÃ¡mara, Giroscopio y AcelerÃ³metro.

### Entorno de Desarrollo (Para editar)
* Unity Hub & Unity 2022.3.x
* MÃ³dulo de soporte de compilaciÃ³n para Android.
* API Key vÃ¡lida de [Groq Cloud](https://console.groq.com/).

---

## âš™ï¸ ConfiguraciÃ³n y Uso

1.  **Clonar el repositorio:**
    ```bash
    git clone [https://github.com/tu-usuario/bloom-agent-ar.git](https://github.com/tu-usuario/bloom-agent-ar.git)
    ```
2.  **Configurar API Key:**
    * Navega a `Assets/Scripts/Managers/GroqClient.cs`.
    * Inserta tu API Key en la variable `private string apiKey = "TU_API_KEY";`.
3.  **Build:**
    * En Unity, ve a `File > Build Settings`.
    * Cambia la plataforma a **Android**.
    * Selecciona tu dispositivo y da clic en **Build and Run**.

### GuÃ­a de Usuario
1.  **Escaneo:** Mueve el mÃ³vil suavemente de lado a lado para detectar tu escritorio (verÃ¡s puntos guÃ­a).
2.  **Anclaje:** Toca la pantalla cuando aparezca el indicador visual para "llamar" al Robot.
3.  **Carga:** Selecciona un documento PDF de prueba desde el menÃº flotante.
4.  **Estudio:** Lee la tarjeta hologrÃ¡fica y toca la opciÃ³n correcta. Â¡Observa la reacciÃ³n del robot!

---

## ğŸ“Š Resultados de EvaluaciÃ³n (HCI)

El prototipo fue validado con una muestra de **$n=11$ usuarios** utilizando la escala **SUS (System Usability Scale)**.

| MÃ©trica | Resultado | CalificaciÃ³n |
| :--- | :---: | :--- |
| **Puntaje SUS Global** | **81.1 / 100** | **Excelencia (Grado A-)** |
| IntenciÃ³n de Uso | 4.5 / 5 | Muy Alta |
| Facilidad de Aprendizaje | 4.6 / 5 | Muy Alta |
| Coherencia IA | 91% | AceptaciÃ³n positiva |

> *ConclusiÃ³n:* El sistema es altamente usable y la IA genera contenido pedagÃ³gicamente pertinente. La principal Ã¡rea de mejora detectada es la optimizaciÃ³n del escaneo de superficies inicial.

---

## ğŸ‘¥ CrÃ©ditos

[cite_start]**Autor:** Steven Ernesto Luna Gaona [cite: 10]
[cite_start]**InstituciÃ³n:** Universidad Nacional de Loja - Carrera de ComputaciÃ³n[cite: 1, 7].
[cite_start]**Asignatura:** Human-Computer Interaction[cite: 8].
**Docente:** Ing. [cite_start]Pablo F. OrdoÃ±ez O.[cite: 15].
